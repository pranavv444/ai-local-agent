
# ARIA  
**Automated Responsive Intelligent Assistant**

ARIA is a desktopâ€‘based AI assistant powered by LangChain and Ollama. It automates Telegram messaging, , controls apps (Notepad, Paint,  play songs on Spotify),fetches  restaurant reviews , manages system functions (volume, lock, shutdown/restart), and drives your browser (Google, YouTube, any site) â€” all handsâ€‘free.

---

## ğŸ” Features

- Naturalâ€‘language querying over a local review database  
- Voice & text modes: talk or type your requests  
- Desktop control:
  - Open/close apps (Notepad, Paint, Spotify)
  - Play/pause Spotify
- Telegram automation:
  - Open chat, search by contact, send messages
- System commands:
  - Volume up/down/mute
  - Lock screen
  - Schedule or cancel shutdown/restart
- Browser automation:
  - Google or YouTube searches
  - Open any URL

---

## ğŸ“‹ Prerequisites

1. OS: WindowsÂ 11  
2. Python â‰¥Â 3.8  
3. Ollama CLI installed and running locally  
   - Using llama3.1 (fits my PC specs) â€” feel free to pick another model
4. Embedding model
   - Using mxbai-embed-large â€” you can swap in another

---

## âš™ï¸ Configuration & Usage

1. **Clone the repo**:
   ```bash
   git clone https://github.com/pranavv444/ai-local-agent.git
   cd ai-local-agent


2. (Optional) Create a virtual environment:

   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Prepare vector database (first run only):

   ```bash
   python vector.py
   ```

5. Telemetry settings are in `config.py` (disabled by default):

   ```python
   import os
   os.environ["CHROMA_TELEMETRY"]      = "false"
   os.environ["ANONYMIZED_TELEMETRY"] = "false"
   ```

6. Model configuration:

   * Chat LLM (`main.py`):

     ```python
     model = OllamaLLM(model="llama3.1")
     ```
   * Embeddings (`vector.py`):

     ```python
     embeddings = OllamaEmbeddings(model="mxbai-embed-large")
     ```

7. Run ARIA:

   ```bash
   # Text mode
   python main.py
   # Choose "1" and type your request

   # Voice mode
   python main.py
   # Choose "2" and speak into your microphone

   # Exit
   # Choose "3" or type "exit"
   ```

**Examples:**

```
What highly rated pizza spots are near me?
Send "Hey, are we still on for tonight?" to Alice
Turn volume up
Search YouTube for "lofi hip hop"
```

---

## ğŸ“‚ File Structure

```
â”œâ”€â”€ app_control.py      # Windows app & system automation
â”œâ”€â”€ config.py           # Telemetry settings
â”œâ”€â”€ main.py             # Entry point & LLM orchestration
â”œâ”€â”€ realistic_restaurant_reviews.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ vector.py           # Build/query local review embeddings
â”œâ”€â”€ chrome_langchain_db # ChromaDB folder
â””â”€â”€ .gitignore
```

---

## ğŸ§° Tech Stack

* Python (core logic)
* LangChain (agent orchestration)
* Ollama (LLM inference & embeddings)
* PyAutoGUI / Pynput (UI control)
* ChromaDB (local vector store)

---

## ğŸ”­ Roadmap

1. **Dynamic Skill Generation**: Use the LLM to generate new skills on the fly.
2. **Visionâ€‘Based UI Interaction**: Integrate a vision layer for screen parsing and decision making.
3. **Memory & Context**: Add longâ€‘term memory for multiâ€‘step workflows.
4. **Plugin Architecture**: Enable thirdâ€‘party plugins and modular extensions.
5. **Enhanced Error Handling**: Build an evaluator/fixer loop for robust execution.
6. **Crossâ€‘Platform Support**: Extend compatibility beyond Windows.

---

