
# ARIA  
**Automated Responsive Intelligent Assistant**

ARIA is a desktopâ€based AI assistant powered by LangChain and Ollama. It can automate Telegram messages , control your desktop apps (Notepad, Paint, Play songs on  Spotify), fetch relevant restaurant reviews ,manage system functions (volume, lock, shutdown/restart), and drive your browser (Google, YouTube, any website) â€” all handsâ€‘free.

---

## ğŸ” Features

- **Naturalâ€‘language querying** over a local review database  
- **Voice & text modes**: talk or type your requests  
- **Desktop control**  
  - Open/close apps (Notepad, Paint, Spotify)  
  - Play/pause Spotify  
- **Telegram automation**  
  - Open chat, search by contact, send messages  
- **System commands**  
  - Volume up/down/mute  
  - Lock screen  
  - Schedule or cancel shutdown/restart  
- **Browser automation**  
  - Google or YouTube searches  
  - Open any URL  

---

## ğŸ“‹ Prerequisites

1. **OS**: WindowsÂ 11  
2. **Python** â‰¥Â 3.8  
3. **Ollama CLI** installed and running locally  
   - Using **llama3.1** (fits my PC specs) â€” feel free to pick another model  
4. **Embedding model**  
   - Using `mxbai-embed-large` â€” you can swap in another embedding model  

---

## âš™ï¸ Configuration & Usage

1. **Clone the repo**  
   ```bash
   git clone https://github.com/pranavv444/ai-local-agent.git aria
   cd aria
````

2. **(Optional) Create a virtual environment**

   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Prepare vector database**  (only on first run)

   ```bash
   python vector.py
   ```

5. **Telemetry settings** are in `config.py` (disabled by default):

   ```python
   import os
   os.environ["CHROMA_TELEMETRY"]      = "false"
   os.environ["ANONYMIZED_TELEMETRY"] = "false"
   ```

6. **Model configuration**

   * Chat LLM (`main.py`):

     ```python
     model = OllamaLLM(model="llama3.1")
     ```
   * Embeddings (`vector.py`):

     ```python
     embeddings = OllamaEmbeddings(model="mxbai-embed-large")
     ```

7. **Run ARIA**

   ```bash
   # Text mode
   python main.py
   # Choose â€œ1â€ and type your request

   # Voice mode
   python main.py
   # Choose â€œ2â€ and speak into your microphone

   # Exit
   # Choose â€œ3â€ or type â€œexitâ€
   ```

**Example requests:**

* Find pizza spots:

  ```
  What highly rated pizza spots are near me?
  ```
* Send Telegram message:

  ```
  Send "Hey, are we still on for tonight?" to Alice
  ```
* Control volume:

  ```
  Turn volume up
  ```
* Search YouTube:
  ```
  Search YouTube for "lofi hip hop"
  ```

---

## ğŸ“‚ File Structure

```
â”œâ”€â”€ app_control.py      # Windows app & system automation
â”œâ”€â”€ config.py           # Telemetry settings
â”œâ”€â”€ main.py             # Entry point & LLM orchestration
â”œâ”€â”€ realistic_restaurant_reviews.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ vector.py           # Build/query local review embeddings
â”œâ”€â”€ chrome_langchain_db # Persisted ChromaDB folder
â””â”€â”€ .gitignore
```
